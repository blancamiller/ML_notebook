{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW3: Classify the Digits Data Set Using Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blanca Miller\n",
    "<br>\n",
    "STAT 760 \n",
    "<br>\n",
    "02/15/2018\n",
    "\n",
    "__Objective:__ Using the MNIST data set, reduce the dimensionality of the training data using eigenvalues and classify the test data according to the chosen features. This approach is called principal component analysis (pca). Decomposing a multivariate data set using a set of orthogonal components (eigenvalues) allows the maximum information about the data to be held, while simplifying & generalizing the model for test data. After reducing the dimensionality of the data set, the Mahalanobis distance is used to classify the testing data set. The Mahalanobis Distance provides a means of computing the corresponding probability for each data point and every class in the set.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEPS\n",
    "1. Import librabries\n",
    "2. Import data sets\n",
    "3. Standardize data\n",
    "4. Run PCA to choose max components and reduce the data's dimensionality\n",
    "5. Compute mean and standard deviation for each class\n",
    "6. Plot the gaussian distribution for each class\n",
    "7. Use Mahalanobis' Distance to compute the probability of test data being in each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set\n",
    "- Each data point is an 8x8 image of a digit\n",
    "- 10 classes compose the target set \n",
    "- ~180 samples per class\n",
    "- 1797 total samples \n",
    "- Data set integers: 0-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import decomposition, datasets, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.spatial.distance import mahalanobis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Digits Training & Testing Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digits data set: (1797, 64)\n",
      "X_train data set: (1203, 64)\n",
      "y_train target array: (1203,)\n",
      "X_test data set: (594, 64)\n",
      "y_test target array: (594,)\n"
     ]
    }
   ],
   "source": [
    "# Load the data set\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Training data set\n",
    "X_digits = digits.data\n",
    "\n",
    "# Target data set \n",
    "y_digits = digits.target\n",
    "\n",
    "# Allocate 2/3 of the data set as training & 1/3 as testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits, test_size=0.33)\n",
    "\n",
    "# Print size of data subsets to verify splitting\n",
    "print(\"Digits data set: {}\".format(digits.data.shape))\n",
    "print(\"X_train data set: {}\".format(X_train.shape))\n",
    "print(\"y_train target array: {}\".format(y_train.shape))\n",
    "print(\"X_test data set: {}\".format(X_test.shape))\n",
    "print(\"y_test target array: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc1d5aa5650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc1d5aa5610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print digits data point to verify data loading\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          1.80816847  1.20149168 ...,  0.70306426  0.20659703\n",
      "  -0.20022674]\n",
      " [ 0.         -0.32545259  0.99234764 ...,  0.19386119 -0.5151926\n",
      "  -0.20022674]\n",
      " [ 0.         -0.32545259  0.3649155  ..., -1.16401368 -0.5151926\n",
      "  -0.20022674]\n",
      " ..., \n",
      " [ 0.         -0.32545259 -0.05337259 ..., -1.16401368 -0.5151926\n",
      "  -0.20022674]\n",
      " [ 0.         -0.32545259 -0.68080472 ...,  1.55173606  2.37196594\n",
      "   0.33863852]\n",
      " [ 0.         -0.32545259 -1.09909281 ...,  0.87279862 -0.27459606\n",
      "  -0.20022674]]\n"
     ]
    }
   ],
   "source": [
    "# Standardize trainging set to equally weight each component \n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_test = preprocessing.scale(X_test)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: Compute the Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(features, targets, n_label):\n",
    "    counter = 0\n",
    "    n_avg = np.zeros_like(features[0])\n",
    "    \n",
    "    # loop through labels matrix to find all instances of n_label\n",
    "    for i in range(features.shape[0]):\n",
    "        \n",
    "        if targets[i] == n_label:\n",
    "            \n",
    "            # sum the values for the ith row to the average vector\n",
    "            n_avg += features[i]\n",
    "            \n",
    "            # count the number of instances of the n_label \n",
    "            counter += 1\n",
    "    \n",
    "    # divide the vector by the number of total n_labels\n",
    "    n_avg /= counter\n",
    "    \n",
    "    return n_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: Compute the Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov(features, targets, n_label):\n",
    "    counter = 0\n",
    "    covariance = np.zeros((features.shape[1],features.shape[1]))\n",
    "    \n",
    "    for i in range(features.shape[0]):\n",
    "        if targets[i] == n_label:\n",
    "            \n",
    "            # sum the n_label values & multiply the data by its transpose \n",
    "            # because we standardized the data, we don't subtract the mean\n",
    "            covariance += np.outer(features[i], features[i])\n",
    "            counter += 1     \n",
    "                             \n",
    "    return covariance * (1.0 / (counter-1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: Mahalanobis Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pass in each n_label vector & compute a distance \n",
    "def maha_dist(x, mu, sigma):\n",
    "    \n",
    "    # take the difference of each n_label vector and the mean vector\n",
    "    diff = x - mu\n",
    "    \n",
    "    inv_sigma = np.linalg.inv(sigma)\n",
    "    \n",
    "    # multiply the inverse of the covariance matrix by the difference\n",
    "    temp = np.dot(inv_sigma, diff)\n",
    "    \n",
    "    # dot functions takes care of the transpose for you b/c \"dot\" is the same as inner product\n",
    "    return np.dot(diff, temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(k, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Construct object representing PCA operation, executed by \"fit\" method: \n",
    "    # argument specifies the number of principal components to reduce data to\n",
    "    pca_train = decomposition.PCA(n_components = k)\n",
    "    pca_test = decomposition.PCA(n_components = k)\n",
    "    \n",
    "    # Execute PCA: identifies n components \n",
    "    pca_train.fit(X_train)\n",
    "    pca_test.fit(X_test)\n",
    "    \n",
    "    # Project data: n dimensional reduced representation\n",
    "    X_train_trans = pca_train.transform(X_train)\n",
    "    X_test_trans = pca_test.transform(X_test)\n",
    "    \n",
    "    # compute the mean for each class/target\n",
    "    mus = [mean(X_train_trans, y_train, n_label) for n_label in range(10)]\n",
    "    \n",
    "    # compute the covariance matrix for each class/target\n",
    "    sigmas = [cov(X_train_trans, y_train, n_label) for n_label in range(10)]    \n",
    "    \n",
    "    # compute the predicted response for the test set using the mahalanobis distance \n",
    "    y_hats = np.zeros(X_test_trans.shape[0])\n",
    "    \n",
    "    # loop through each test vector\n",
    "    for i in range(X_test_trans.shape[0]): \n",
    "        distance = np.inf\n",
    "        index = -1\n",
    "        \n",
    "        # loop through each class/target for each test vector\n",
    "        for j in range(10):\n",
    "            d = mahalanobis(X_test_trans[i], mus[j], sigmas[j])\n",
    "            if d < distance:\n",
    "                distance = d\n",
    "                index = j\n",
    "                \n",
    "        # array of predictions\n",
    "        y_hats[i] = index\n",
    "    \n",
    "    # compute rss for classification model on test set\n",
    "    return (1.0/X_test_trans.shape[0]) * np.sqrt(np.sum((y_test - y_hats) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'sqrt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d4540c4f8a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrsses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrsses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrsses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6cb370591e2c>\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(k, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# compute rss for classification model on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mX_test_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_hats\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: global name 'sqrt' is not defined"
     ]
    }
   ],
   "source": [
    "rsses = np.zeros(64)\n",
    "error = np.inf\n",
    "index = -1\n",
    "for k in range(1, 64):\n",
    "    rsses[k] = eval_model(k, X_train, y_train, X_test, y_test)\n",
    "    if rsses[k] < error:\n",
    "        error = rsses[k]\n",
    "        index = k\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph scatter plot\n",
    "x = range(1,64)\n",
    "y = rsses[1:]\n",
    "\n",
    "print(y.shape)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "#plt.title(\"All Possible Subset Models for Prostate Cancer Data\")\n",
    "#plt.xlabel(\"Subset Size k\")\n",
    "#plt.ylabel(\"Residual Sum-Of-Squares\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
