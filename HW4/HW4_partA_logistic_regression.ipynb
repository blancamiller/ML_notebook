{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4 Part A: Logistic Regression for Digits Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blanca Miller\n",
    "<br>\n",
    "CS 791\n",
    "<br>\n",
    "03/02/2018\n",
    "\n",
    "__Objective:__ Generate a logistic regression model to model the probabilities for K classes. We estimate the probability of a  dependent/response variable using p(x, beta) = exp(beta^T * x)/(1 + exp(beta^T * x)), where x represents our data and beta represents the model parameters. We use the maximum likelihood method to pick parameters, starting with a random set of parameters, and iterate to maximize the likelihood.  \n",
    "\n",
    "The probability is bounded from [0, 1]. The outputted probability p(x, beta) represents the likelihood that data value, x, belongs to a particular class (or positive class for the binary case).  \n",
    "\n",
    "__Digits Data Set:__ https://web.stanford.edu/~hastie/ElemStatLearn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEPS\n",
    "1. Import libraries\n",
    "2. Import data sets: train & test sets\n",
    "3. Convert data frame into numpy array\n",
    "4. Parse the data into two matrices:\n",
    "    - X: design matrix\n",
    "    - y: response/prediction vector\n",
    "5. Standardize to make the magnitude of your inputs roughly equal to the magnitude of your weights\n",
    "6. Estimate the weights\n",
    "7. Calculate gradient\n",
    "8. Graph gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS\n",
    "- Count the number of instances of two chosen classes using the y(response/prediction) vector\n",
    "- Train the logistic model based on two chosen classes \n",
    "- Test the model based on the the two chosen classes\n",
    "- beta(weights), X(feature/predictor) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA SET\n",
    "- 7291 training observations\n",
    "- 2007 testing observations\n",
    "- 16 x 16 grayscale images of digits\n",
    "- Each row consists of the digit id (0-9) followed by the 256 grayscale values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "from scipy.stats  import spearmanr\n",
    "from pylab import rcParams\n",
    "#import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('digits_data.train', delimiter=' ', header=None)\n",
    "test = pd.read_csv('digits_data.test', delimiter=' ', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (7291, 258)\n",
      "Testing Set: (2007, 257)\n"
     ]
    }
   ],
   "source": [
    "# print size of data sets\n",
    "print(\"Training Set: {}\".format(train.shape))\n",
    "print(\"Testing Set: {}\".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>0.862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.482</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.813</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.809</td>\n",
       "      <td>-0.887</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.828</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.450</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.928</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.439</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-0.883</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3      4      5      6      7      8      9   ...     248  \\\n",
       "0  6.0 -1.0 -1.0 -1.0 -1.000 -1.000 -1.000 -1.000 -0.631  0.862 ...   0.823   \n",
       "1  5.0 -1.0 -1.0 -1.0 -0.813 -0.671 -0.809 -0.887 -0.671 -0.853 ...  -0.671   \n",
       "2  4.0 -1.0 -1.0 -1.0 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 ...  -1.000   \n",
       "3  7.0 -1.0 -1.0 -1.0 -1.000 -1.000 -0.273  0.684  0.960  0.450 ...   1.000   \n",
       "4  3.0 -1.0 -1.0 -1.0 -1.000 -1.000 -0.928 -0.204  0.751  0.466 ...   0.639   \n",
       "\n",
       "     249    250    251    252    253    254    255  256  257  \n",
       "0  1.000  0.482 -0.474 -0.991 -1.000 -1.000 -1.000 -1.0  NaN  \n",
       "1 -0.033  0.761  0.762  0.126 -0.095 -0.671 -0.828 -1.0  NaN  \n",
       "2 -1.000 -0.109  1.000 -0.179 -1.000 -1.000 -1.000 -1.0  NaN  \n",
       "3  0.536 -0.987 -1.000 -1.000 -1.000 -1.000 -1.000 -1.0  NaN  \n",
       "4  1.000  1.000  0.791  0.439 -0.199 -0.883 -1.000 -1.0  NaN  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print observations for training set\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.948</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.384</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.908</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.622</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.858</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3      4    5      6      7      8      9   ...     247  \\\n",
       "0    9 -1.0 -1.0 -1.0 -1.000 -1.0 -0.948 -0.561  0.148  0.384 ...  -1.000   \n",
       "1    6 -1.0 -1.0 -1.0 -1.000 -1.0 -1.000 -1.000 -1.000 -1.000 ...  -1.000   \n",
       "2    3 -1.0 -1.0 -1.0 -0.593  0.7  1.000  1.000  1.000  1.000 ...   1.000   \n",
       "3    6 -1.0 -1.0 -1.0 -1.000 -1.0 -1.000 -1.000 -1.000 -1.000 ...  -1.000   \n",
       "4    6 -1.0 -1.0 -1.0 -1.000 -1.0 -1.000 -1.000 -0.858 -0.106 ...   0.901   \n",
       "\n",
       "     248    249    250    251    252  253  254  255  256  \n",
       "0 -0.908  0.430  0.622 -0.973 -1.000 -1.0 -1.0 -1.0 -1.0  \n",
       "1 -1.000 -1.000 -1.000 -1.000 -1.000 -1.0 -1.0 -1.0 -1.0  \n",
       "2  0.717  0.333  0.162 -0.393 -1.000 -1.0 -1.0 -1.0 -1.0  \n",
       "3 -1.000 -1.000 -1.000 -1.000 -1.000 -1.0 -1.0 -1.0 -1.0  \n",
       "4  0.901  0.901  0.290 -0.369 -0.867 -1.0 -1.0 -1.0 -1.0  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print observations for testing data set\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data Frame into Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train.as_matrix()\n",
    "test_set = test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.   , -1.   , -1.   , ..., -1.   , -1.   ,    nan],\n",
       "       [-1.   , -1.   , -1.   , ..., -0.828, -1.   ,    nan],\n",
       "       [-1.   , -1.   , -1.   , ..., -1.   , -1.   ,    nan],\n",
       "       ..., \n",
       "       [-1.   , -1.   , -1.   , ..., -1.   , -1.   ,    nan],\n",
       "       [-1.   , -1.   , -1.   , ..., -1.   , -1.   ,    nan],\n",
       "       [-1.   , -1.   , -1.   , ..., -1.   , -1.   ,    nan]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all rows, start at the 1st column until the end of the matrix\n",
    "train_set[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.,  5.,  4., ...,  3.,  0.,  1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the Data from the Targets/Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (7291, 256)\n",
      "Training Labels: (7291,)\n",
      "Testing Data: (2007, 256)\n",
      "Testing Labels: (2007,)\n"
     ]
    }
   ],
   "source": [
    "# for all rows, start at the 1st column and go until the end of the column\n",
    "X_train = train_set[:,1:257] # got to 256 to remove NaN column that numpy inserted\n",
    "\n",
    "# for alls rows, get only the 0th element\n",
    "y_train = train_set[:,0]\n",
    "\n",
    "# for all rows, start at the 1st column and go until the end of the column\n",
    "X_test = test_set[:,1:]\n",
    "\n",
    "# foall rows, get only the 0th element\n",
    "y_test = test_set[:,0]\n",
    "\n",
    "print(\"Training Data: {}\".format(X_train.shape))\n",
    "print(\"Training Labels: {}\".format(y_train.shape))\n",
    "print(\"Testing Data: {}\".format(X_test.shape))\n",
    "print(\"Testing Labels: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize for Similar Input & Weight Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.80693359 -0.80693359 -0.80693359 ..., -0.80693359 -0.80693359\n",
      "  -0.80693359]\n",
      " [-1.0229121  -1.0229121  -1.0229121  ..., -0.64403944 -0.82483886\n",
      "  -1.0229121 ]\n",
      " [-0.62434198 -0.62434198 -0.62434198 ..., -0.62434198 -0.62434198\n",
      "  -0.62434198]\n",
      " ..., \n",
      " [-0.88870472 -0.88870472 -0.88870472 ..., -0.88870472 -0.88870472\n",
      "  -0.88870472]\n",
      " [-1.34819665 -1.34819665 -1.34819665 ..., -1.34819665 -1.34819665\n",
      "  -1.34819665]\n",
      " [-0.66492726 -0.66492726 -0.66492726 ..., -0.66492726 -0.66492726\n",
      "  -0.66492726]]\n"
     ]
    }
   ],
   "source": [
    "# Set axis to 1 to standardize per sample/vector, rather than standardize each feature\n",
    "X_train = preprocessing.scale(X_train, axis=1)\n",
    "X_test = preprocessing.scale(X_test, axis=1)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designate Two Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.0\n",
    "b = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the Number of Instances of the Two Chosen Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many observations account for class a & b\n",
    "def ab_count(X, y, a, b):\n",
    "    \n",
    "    # initialize count \n",
    "    n = 0\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        \n",
    "        # identify class a or b in label vector y\n",
    "        if (y[i] == a or y[i] == b):\n",
    "        \n",
    "            # increment the count\n",
    "            n += 1\n",
    "        \n",
    "    # return the count\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2199"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_samples = ab_count(X_train, y_train, a, b)\n",
    "ab_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill a Matrix with the Number Count of the Two Chosen Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of rows for classes a & b \n",
    "training_data = np.zeros((X.shape[0], X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Logistic Model with the Training Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression score: 0.982169798382\n"
     ]
    }
   ],
   "source": [
    "print(\"LogisticRegression score: {}\".format(logistic.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpretation:__ A score of 0.98 means that our model can predict the correct label for a given digit 98% of the time!! This value is just shy of ideal, 1.0, which would mean our model was correctly predicted the label 100% of the time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model's Precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      1194\n",
      "        1.0       1.00      1.00      1.00      1005\n",
      "        2.0       0.99      0.97      0.98       731\n",
      "        3.0       0.99      0.98      0.98       658\n",
      "        4.0       0.96      0.97      0.97       652\n",
      "        5.0       0.97      0.97      0.97       556\n",
      "        6.0       0.99      0.99      0.99       664\n",
      "        7.0       0.98      0.99      0.99       645\n",
      "        8.0       0.96      0.95      0.95       542\n",
      "        9.0       0.98      0.98      0.98       644\n",
      "\n",
      "avg / total       0.98      0.98      0.98      7291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = logistic.predict(X_train)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpretation:__ The model's overall precision for all 10 classes is 0.98.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training samples (rows)\n",
    "n_trains = X_train.shape[0]\n",
    "\n",
    "# Number of features (columns)\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "# Number of classes\n",
    "n_classes = 10\n",
    "classes = np.asarray([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0])\n",
    "\n",
    "# Chosen Classes\n",
    "a = 0.0\n",
    "b = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the logistic regression model according to the two chosen classes\n",
    "def train_model(X, y, a, b, ab_size):\n",
    "    \n",
    "    # count the number of rows for classes a & b \n",
    "    training_data = np.zeros((X.shape[0], X.shape[1]))\n",
    "    \n",
    "    # loop through the training rows/observations\n",
    "    for i in range(X.shape[0]):\n",
    "        \n",
    "        # identify label a or label b in y vector\n",
    "        if y[i] == a or y[i] == b:\n",
    "            \n",
    "            # Add the identified data to the training set\n",
    "            training_data[ab_size] += X[i] \n",
    "        \n",
    "            # run log reg for class a & b\n",
    "            logistic = LogisticRegression()\n",
    "            logistic.fit(training_data, y)\n",
    "        \n",
    "        \n",
    "        \n",
    "            #score = logistic.fit(X_train, y_train).score(X_test, y_test)\n",
    "        \n",
    "    #return parameter_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic.predict?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this does what the test model function does \n",
    "logistic.predict(X, y)\n",
    "\n",
    "# the last step \n",
    "# count how many of the y_test match y_train\n",
    "\n",
    "\n",
    "def test_model(X, y, model):\n",
    "    \n",
    "    # beta * x: this product computes the entire dot product for each row (no loop!)\n",
    "    betax = np.dot(X, model)\n",
    "        \n",
    "    # compute y_hat using the logistic function, the sigmoid function \n",
    "    y_hat = 1.0 / (1.0 + np.exp(-betax))\n",
    "    \n",
    "    #y_hat needs to be rounded\n",
    "    np.round(y_hat)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray([-1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26894142,  0.88079708,  0.95257413,  0.98201379])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# component \n",
    "y = 1.0/(1.0+np.exp(-x))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.matrix([[-1, 2, 3, 4],[5, 6, 7, 8]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.26894142,  0.88079708,  0.95257413,  0.98201379],\n",
       "        [ 0.99330715,  0.99752738,  0.99908895,  0.99966465]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_A = 1.0/(1.0+np.exp(-A))\n",
    "y_hat_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_hat_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = logistic.fit(X_train, y_train).score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
