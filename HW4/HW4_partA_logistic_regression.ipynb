{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4 Part A: Logistic Regression for Digits Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blanca Miller\n",
    "<br>\n",
    "CS 791\n",
    "<br>\n",
    "03/01/2018\n",
    "\n",
    "__Objective:__ Generate a logistic regression model to model the probabilities for K classes. We estimate the probability of a  dependent/response variable using p(x, beta) = exp(beta^T * x)/(1 + exp(beta^T * x)), where x represents our data and beta represents the model parameters. We use the maximum likelihood method to pick parameters, starting with a random set of parameters, and iterate to maximize the likelihood.  \n",
    "\n",
    "The probability is bounded from [0, 1]. The outputted probability p(x, beta) represents the likelihood that data value, x, belongs to a particular class (or positive class for the binary case).  \n",
    "\n",
    "__Digits Data Set:__ https://web.stanford.edu/~hastie/ElemStatLearn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEPS\n",
    "\n",
    "Setup:\n",
    "1. Import libraries\n",
    "2. Import data sets: train & test sets\n",
    "3. Convert data frame into numpy array\n",
    "4. Parse the data into two matrices:\n",
    "    - X: design matrix\n",
    "    - y: targets/labels/response vector\n",
    "5. Standardize to make the magnitude of your inputs roughly equal to the magnitude of your weights\n",
    "\n",
    "Training:\n",
    "1. Set the pairs of classes to compare\n",
    "2. Count the number of training samples for the pair of classes \n",
    "3. Initilaize training matrices with corresponding count for each pair of chosen classes\n",
    "4. Fill training matrices with corresponding data for each pair of chosen classes\n",
    "\n",
    "Testing:\n",
    "1. Count the number of testing samples for the pair of classes \n",
    "2. Initilaize testing matrices with corresponding count for each pair of chosen classes\n",
    "3. Fill testing matrices with corresponding data for each pair of chosen classes\n",
    "4. Make predictions about new data according to the chosen pair of classes\n",
    "5. Compare the Test & Train Sets Labels for Accuracy\n",
    "6. Evaluate Model's Precision for Each Pair of Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS\n",
    "- Count the number of instances of two chosen classes using the y(response/prediction) vector\n",
    "- Train the logistic model based on two chosen classes \n",
    "- Test the model based on the the two chosen classes\n",
    "- beta(weights), X(feature/predictor) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA SET\n",
    "- 7291 training observations\n",
    "- 2007 testing observations\n",
    "- 16 x 16 grayscale images of digits\n",
    "- Each row consists of the digit id (0-9) followed by the 256 grayscale values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "from scipy.stats  import spearmanr\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('digits_data.train', delimiter=' ', header=None)\n",
    "test = pd.read_csv('digits_data.test', delimiter=' ', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (7291, 258)\n",
      "Testing Set: (2007, 257)\n"
     ]
    }
   ],
   "source": [
    "# print size of data sets\n",
    "print(\"Training Set: {}\".format(train.shape))\n",
    "print(\"Testing Set: {}\".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>0.862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.482</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.813</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.809</td>\n",
       "      <td>-0.887</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.828</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.450</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.928</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.439</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-0.883</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3      4      5      6      7      8      9   ...     248  \\\n",
       "0  6.0 -1.0 -1.0 -1.0 -1.000 -1.000 -1.000 -1.000 -0.631  0.862 ...   0.823   \n",
       "1  5.0 -1.0 -1.0 -1.0 -0.813 -0.671 -0.809 -0.887 -0.671 -0.853 ...  -0.671   \n",
       "2  4.0 -1.0 -1.0 -1.0 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 ...  -1.000   \n",
       "3  7.0 -1.0 -1.0 -1.0 -1.000 -1.000 -0.273  0.684  0.960  0.450 ...   1.000   \n",
       "4  3.0 -1.0 -1.0 -1.0 -1.000 -1.000 -0.928 -0.204  0.751  0.466 ...   0.639   \n",
       "\n",
       "     249    250    251    252    253    254    255  256  257  \n",
       "0  1.000  0.482 -0.474 -0.991 -1.000 -1.000 -1.000 -1.0  NaN  \n",
       "1 -0.033  0.761  0.762  0.126 -0.095 -0.671 -0.828 -1.0  NaN  \n",
       "2 -1.000 -0.109  1.000 -0.179 -1.000 -1.000 -1.000 -1.0  NaN  \n",
       "3  0.536 -0.987 -1.000 -1.000 -1.000 -1.000 -1.000 -1.0  NaN  \n",
       "4  1.000  1.000  0.791  0.439 -0.199 -0.883 -1.000 -1.0  NaN  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print observations for training set\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.948</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.384</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.908</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.622</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.858</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3      4    5      6      7      8      9   ...     247  \\\n",
       "0    9 -1.0 -1.0 -1.0 -1.000 -1.0 -0.948 -0.561  0.148  0.384 ...  -1.000   \n",
       "1    6 -1.0 -1.0 -1.0 -1.000 -1.0 -1.000 -1.000 -1.000 -1.000 ...  -1.000   \n",
       "2    3 -1.0 -1.0 -1.0 -0.593  0.7  1.000  1.000  1.000  1.000 ...   1.000   \n",
       "3    6 -1.0 -1.0 -1.0 -1.000 -1.0 -1.000 -1.000 -1.000 -1.000 ...  -1.000   \n",
       "4    6 -1.0 -1.0 -1.0 -1.000 -1.0 -1.000 -1.000 -0.858 -0.106 ...   0.901   \n",
       "\n",
       "     248    249    250    251    252  253  254  255  256  \n",
       "0 -0.908  0.430  0.622 -0.973 -1.000 -1.0 -1.0 -1.0 -1.0  \n",
       "1 -1.000 -1.000 -1.000 -1.000 -1.000 -1.0 -1.0 -1.0 -1.0  \n",
       "2  0.717  0.333  0.162 -0.393 -1.000 -1.0 -1.0 -1.0 -1.0  \n",
       "3 -1.000 -1.000 -1.000 -1.000 -1.000 -1.0 -1.0 -1.0 -1.0  \n",
       "4  0.901  0.901  0.290 -0.369 -0.867 -1.0 -1.0 -1.0 -1.0  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print observations for testing data set\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data Frame into Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = train.as_matrix()\n",
    "test_set = test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.   , -1.   , -1.   , ..., -1.   , -1.   ,    nan],\n",
       "       [-1.   , -1.   , -1.   , ..., -0.828, -1.   ,    nan],\n",
       "       [-1.   , -1.   , -1.   , ..., -1.   , -1.   ,    nan],\n",
       "       ..., \n",
       "       [-1.   , -1.   , -1.   , ..., -1.   , -1.   ,    nan],\n",
       "       [-1.   , -1.   , -1.   , ..., -1.   , -1.   ,    nan],\n",
       "       [-1.   , -1.   , -1.   , ..., -1.   , -1.   ,    nan]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print all rows, start at the 1st column until the end of the matrix\n",
    "train_set[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.,  5.,  4., ...,  3.,  0.,  1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print all rows in 0th column\n",
    "train_set[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the Data from the Targets/Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (7291, 256)\n",
      "Training Labels: (7291,)\n",
      "Testing Data: (2007, 256)\n",
      "Testing Labels: (2007,)\n",
      "Number of Training Samples: 7291\n",
      "Number of Data Features: 256\n"
     ]
    }
   ],
   "source": [
    "# for all rows, start at the 1st column and go until the end of the column\n",
    "X_train = train_set[:,1:257] # got to 256 to remove NaN column that numpy inserted\n",
    "\n",
    "# for alls rows, get only the 0th element\n",
    "y_train = train_set[:,0]\n",
    "\n",
    "# for all rows, start at the 1st column and go until the end of the column\n",
    "X_test = test_set[:,1:]\n",
    "\n",
    "# foall rows, get only the 0th element\n",
    "y_test = test_set[:,0]\n",
    "\n",
    "# Number of training samples (rows)\n",
    "n_trains = X_train.shape[0]\n",
    "\n",
    "# Number of features (columns)\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "print(\"Training Data: {}\".format(X_train.shape))\n",
    "print(\"Training Labels: {}\".format(y_train.shape))\n",
    "print(\"Testing Data: {}\".format(X_test.shape))\n",
    "print(\"Testing Labels: {}\".format(y_test.shape))\n",
    "print(\"Number of Training Samples: {}\".format(n_trains))\n",
    "print(\"Number of Data Features: {}\".format(n_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize for Similar Input & Weight Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.80693359 -0.80693359 -0.80693359 ..., -0.80693359 -0.80693359\n",
      "  -0.80693359]\n",
      " [-1.0229121  -1.0229121  -1.0229121  ..., -0.64403944 -0.82483886\n",
      "  -1.0229121 ]\n",
      " [-0.62434198 -0.62434198 -0.62434198 ..., -0.62434198 -0.62434198\n",
      "  -0.62434198]\n",
      " ..., \n",
      " [-0.88870472 -0.88870472 -0.88870472 ..., -0.88870472 -0.88870472\n",
      "  -0.88870472]\n",
      " [-1.34819665 -1.34819665 -1.34819665 ..., -1.34819665 -1.34819665\n",
      "  -1.34819665]\n",
      " [-0.66492726 -0.66492726 -0.66492726 ..., -0.66492726 -0.66492726\n",
      "  -0.66492726]]\n"
     ]
    }
   ],
   "source": [
    "# Set axis to 1 to standardize per sample/vector, rather than standardize each feature\n",
    "X_train = preprocessing.scale(X_train, axis=1)\n",
    "X_test = preprocessing.scale(X_test, axis=1)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: Count the Number of Samples for a Pair of Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count how many observations account for class a & b\n",
    "def class_count(X, y, a, b):\n",
    "    \n",
    "    # initialize count \n",
    "    n = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        \n",
    "        # identify class a or b in label vector y\n",
    "        if (y[i] == a or y[i] == b):\n",
    "        \n",
    "            # increment the count\n",
    "            n += 1\n",
    "        \n",
    "    # return the count\n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: Fill a Matrix with the Samples for a Pair of Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class_fill(X, y, a, b, size, abX_train, aby_train):\n",
    "    # initialize count\n",
    "    n = 0\n",
    "    for s in range(X.shape[0]):\n",
    "        \n",
    "        # identify class a or b in label vector\n",
    "        if (y[s] == a or y[s] == b):\n",
    "            \n",
    "            # fill matrix with data\n",
    "            abX_train[n] = X[s]\n",
    "            aby_train[n] = y[s]\n",
    "            \n",
    "            # increment count\n",
    "            n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designate Class Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 0.0\n",
    "b = 1.0\n",
    "c = 2.0\n",
    "d = 3.0\n",
    "e = 4.0 \n",
    "f = 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the Number of Training Instances for Each Pair of Chosen Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Samples for Classes A & B: 2199\n",
      "Number of Training Samples for Classes C & D: 1389\n",
      "Number of Training Samples for Classes E & F: 1208\n"
     ]
    }
   ],
   "source": [
    "ab_samples = class_count(X_train, y_train, a, b)\n",
    "cd_samples = class_count(X_train, y_train, c, d)\n",
    "ef_samples = class_count(X_train, y_train, e, f)\n",
    "\n",
    "print(\"Number of Training Samples for Classes A & B: {}\".format(ab_samples))\n",
    "print(\"Number of Training Samples for Classes C & D: {}\".format(cd_samples))\n",
    "print(\"Number of Training Samples for Classes E & F: {}\".format(ef_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initilaize Training Matrices with Corresponding Count for Each Pair of Chosen Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the training data set matrix \n",
    "abX_train = np.zeros((ab_samples, X_train.shape[1]))\n",
    "cdX_train = np.zeros((cd_samples, X_train.shape[1]))\n",
    "efX_train = np.zeros((ef_samples, X_train.shape[1]))\n",
    "\n",
    "# Initialize the targets/labels matrix\n",
    "aby_train = np.zeros((ab_samples, 1))\n",
    "cdy_train = np.zeros((cd_samples, 1))\n",
    "efy_train = np.zeros((ef_samples, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Training Matrices with Corresponding Data for each Pair of Chosen Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Training Matrix for Classes A & B: (2199, 256)\n",
      "Size of Training Matrix for Classes C & D: (1389, 256)\n",
      "Size of Training Matrix for Classes E & F: (1208, 256)\n"
     ]
    }
   ],
   "source": [
    "class_fill(X_train, y_train, a, b, ab_samples, abX_train, aby_train)\n",
    "class_fill(X_train, y_train, c, d, cd_samples, cdX_train, cdy_train)\n",
    "class_fill(X_train, y_train, e, f, ef_samples, efX_train, efy_train)\n",
    "\n",
    "print(\"Size of Training Matrix for Classes A & B: {}\".format(abX_train.shape))\n",
    "print(\"Size of Training Matrix for Classes C & D: {}\".format(cdX_train.shape))\n",
    "print(\"Size of Training Matrix for Classes E & F: {}\".format(efX_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Logistic Model with the Training Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Score: 1.0\n",
      "LogisticRegression Score: 1.0\n",
      "LogisticRegression Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "ab_logistic = LogisticRegression()\n",
    "ab_logistic.fit(abX_train, aby_train)\n",
    "\n",
    "cd_logistic = LogisticRegression() \n",
    "cd_logistic.fit(cdX_train, cdy_train)\n",
    "\n",
    "ef_logistic = LogisticRegression()\n",
    "ef_logistic.fit(efX_train, efy_train)\n",
    "\n",
    "print(\"LogisticRegression Score: {}\".format(ab_logistic.score(abX_train, aby_train)))\n",
    "print(\"LogisticRegression Score: {}\".format(cd_logistic.score(cdX_train, cdy_train)))\n",
    "print(\"LogisticRegression Score: {}\".format(ef_logistic.score(efX_train, efy_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpretation:__ A score of 1.0 means that our model can perfectly predict the correct label for a given digit 100% of the time. This value is ideal as we chose samples that exactly matched to our two classes. Normally, we would see some amount of noise in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the Number of Testing Instances for Each Pair of Chosen Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Testing Samples for Classes A & B: 623\n",
      "Number of Testing Samples for Classes C & D: 364\n",
      "Number of Testing Samples for Classes E & F: 360\n"
     ]
    }
   ],
   "source": [
    "ab_test_samples = class_count(X_test, y_test, a, b)\n",
    "cd_test_samples = class_count(X_test, y_test, c, d)\n",
    "ef_test_samples = class_count(X_test, y_test, e, f)\n",
    "\n",
    "print(\"Number of Testing Samples for Classes A & B: {}\".format(ab_test_samples))\n",
    "print(\"Number of Testing Samples for Classes C & D: {}\".format(cd_test_samples))\n",
    "print(\"Number of Testing Samples for Classes E & F: {}\".format(ef_test_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Testing Matrices with Corresponding Count for Each Pair of Chosen Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the training data set matrix \n",
    "abX_test = np.zeros((ab_test_samples, X_test.shape[1]))\n",
    "cdX_test = np.zeros((cd_test_samples, X_test.shape[1]))\n",
    "efX_test = np.zeros((ef_test_samples, X_test.shape[1]))\n",
    "\n",
    "# Initialize the targets/labels matrix\n",
    "aby_test = np.zeros((ab_test_samples, 1))\n",
    "cdy_test = np.zeros((cd_test_samples, 1))\n",
    "efy_test = np.zeros((ef_test_samples, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Testing Matrices with Corresponding Data for each Pair of Chosen Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Testing Matrix for Classes A & B: (623, 256)\n",
      "Size of Testing Matrix for Classes C & D: (364, 256)\n",
      "Size of Testing Matrix for Classes E & F: (360, 256)\n"
     ]
    }
   ],
   "source": [
    "class_fill(X_test, y_test, a, b, ab_test_samples, abX_test, aby_test)\n",
    "class_fill(X_test, y_test, c, d, cd_test_samples, cdX_test, cdy_test)\n",
    "class_fill(X_test, y_test, e, f, ef_test_samples, efX_test, efy_test)\n",
    "\n",
    "print(\"Size of Testing Matrix for Classes A & B: {}\".format(abX_test.shape))\n",
    "print(\"Size of Testing Matrix for Classes C & D: {}\".format(cdX_test.shape))\n",
    "print(\"Size of Testing Matrix for Classes E & F: {}\".format(efX_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions about New Data According to the Chosen Pair of Classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for Classes A & B: \n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.\n",
      "  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.  1.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  0.  0.  0.  0.  1.  0.\n",
      "  0.  1.  1.  0.  1.  1.  1.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  1.\n",
      "  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.\n",
      "  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.\n",
      "  0.  1.  1.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.  0.  1.\n",
      "  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  0.\n",
      "  0.  1.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.\n",
      "  1.  1.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.  0.  1.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  1.\n",
      "  0.  1.  0.  1.  0.  1.  1.  1.  1.  0.  1.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.\n",
      "  1.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  0.\n",
      "  1.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  1.  1.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.\n",
      "  0.  1.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.  0.  1.  0.\n",
      "  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.\n",
      "  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.\n",
      "  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.\n",
      "  1.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.  1.\n",
      "  1.  0.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  0.  0.\n",
      "  1.  1.  0.  1.  1.  1.  1.  0.  1.  0.  0.  1.  0.  1.  1.  1.  1.  0.\n",
      "  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  0.  1.  1.  0.  1.  1.  1.  0.  1.  1.  0.  1.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.  1.  1.  0.  1.  1.  1.  0.\n",
      "  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.  1.  1.  0.  0.\n",
      "  0.  1.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.\n",
      "  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.]\n",
      "Predictions for Classes C & D: \n",
      "[ 3.  2.  2.  3.  2.  2.  2.  3.  3.  2.  2.  2.  2.  2.  2.  3.  2.  2.\n",
      "  2.  2.  2.  2.  3.  2.  3.  3.  2.  3.  3.  2.  2.  2.  3.  2.  3.  3.\n",
      "  2.  3.  3.  2.  3.  2.  3.  2.  2.  2.  2.  2.  2.  3.  3.  3.  2.  2.\n",
      "  3.  2.  3.  2.  2.  3.  3.  3.  2.  2.  2.  3.  3.  3.  3.  2.  2.  2.\n",
      "  2.  2.  3.  2.  2.  2.  2.  3.  2.  3.  3.  3.  2.  2.  3.  3.  3.  2.\n",
      "  3.  2.  2.  3.  2.  3.  2.  3.  2.  2.  3.  2.  3.  2.  3.  2.  2.  3.\n",
      "  2.  2.  2.  2.  3.  2.  3.  2.  2.  2.  2.  2.  3.  2.  2.  2.  2.  2.\n",
      "  3.  3.  3.  3.  2.  2.  2.  2.  2.  2.  3.  2.  3.  3.  3.  3.  3.  3.\n",
      "  2.  3.  3.  3.  3.  3.  3.  2.  3.  3.  3.  2.  3.  2.  2.  2.  2.  2.\n",
      "  3.  2.  2.  3.  3.  3.  3.  2.  2.  2.  2.  3.  2.  2.  2.  2.  2.  2.\n",
      "  3.  3.  3.  2.  3.  2.  2.  3.  3.  3.  3.  3.  3.  3.  3.  3.  2.  3.\n",
      "  3.  3.  3.  3.  3.  3.  3.  2.  2.  2.  3.  2.  2.  2.  2.  2.  3.  3.\n",
      "  2.  2.  3.  2.  3.  2.  2.  3.  3.  3.  2.  3.  2.  2.  3.  3.  3.  2.\n",
      "  2.  2.  3.  2.  2.  2.  2.  3.  3.  2.  3.  2.  2.  3.  2.  3.  2.  2.\n",
      "  3.  3.  3.  2.  3.  3.  2.  3.  3.  3.  3.  3.  2.  3.  3.  3.  3.  3.\n",
      "  2.  3.  3.  3.  3.  2.  2.  2.  3.  3.  2.  2.  3.  3.  2.  2.  2.  3.\n",
      "  3.  3.  3.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  3.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  2.  3.  2.  2.  2.  3.  2.  2.  3.  2.  3.  2.  2.  2.\n",
      "  3.  3.  2.  3.  3.  3.  2.  2.  3.  3.  2.  2.  3.  2.  2.  2.  2.  2.\n",
      "  3.  3.  3.  3.  2.  2.  2.  3.  2.  2.  3.  3.  2.  2.  2.  3.  3.  3.\n",
      "  2.  3.  2.  3.]\n",
      "Predictions for Classes E & F: \n",
      "[ 4.  4.  5.  5.  4.  5.  5.  4.  4.  4.  5.  5.  5.  4.  4.  5.  4.  4.\n",
      "  4.  4.  4.  4.  4.  4.  5.  5.  4.  4.  5.  5.  5.  4.  5.  5.  4.  4.\n",
      "  4.  4.  4.  4.  5.  5.  5.  4.  5.  4.  4.  4.  5.  4.  4.  5.  5.  4.\n",
      "  5.  5.  5.  4.  4.  4.  4.  4.  4.  5.  4.  4.  4.  4.  5.  5.  5.  4.\n",
      "  4.  4.  4.  4.  5.  5.  4.  5.  4.  5.  5.  4.  5.  5.  5.  5.  4.  4.\n",
      "  5.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  5.  4.  4.  4.  4.  5.  4.\n",
      "  4.  4.  4.  5.  5.  5.  4.  5.  5.  4.  4.  4.  4.  4.  4.  4.  4.  4.\n",
      "  5.  4.  4.  5.  4.  4.  5.  4.  4.  5.  4.  4.  5.  5.  5.  4.  4.  4.\n",
      "  5.  5.  4.  5.  5.  5.  5.  5.  5.  4.  5.  5.  4.  4.  5.  5.  4.  4.\n",
      "  5.  5.  5.  4.  5.  4.  4.  4.  4.  5.  5.  4.  5.  4.  4.  5.  5.  5.\n",
      "  5.  5.  4.  4.  4.  4.  5.  4.  4.  5.  4.  4.  4.  4.  4.  4.  4.  4.\n",
      "  4.  4.  4.  5.  5.  4.  4.  5.  5.  4.  4.  4.  5.  4.  4.  4.  4.  4.\n",
      "  4.  4.  4.  4.  4.  4.  4.  5.  4.  4.  4.  4.  4.  4.  4.  5.  4.  5.\n",
      "  5.  4.  4.  5.  4.  4.  5.  5.  5.  4.  4.  5.  4.  5.  4.  4.  4.  4.\n",
      "  4.  5.  5.  5.  5.  5.  4.  4.  4.  4.  4.  4.  5.  4.  4.  4.  5.  4.\n",
      "  4.  4.  5.  4.  4.  5.  5.  5.  5.  5.  5.  4.  4.  4.  5.  5.  5.  5.\n",
      "  5.  5.  5.  4.  5.  5.  5.  5.  4.  5.  5.  5.  5.  4.  4.  5.  5.  4.\n",
      "  5.  4.  5.  4.  4.  5.  5.  4.  4.  5.  5.  4.  4.  4.  5.  5.  5.  4.\n",
      "  4.  5.  5.  4.  5.  5.  4.  5.  5.  5.  5.  5.  5.  5.  5.  5.  4.  5.\n",
      "  5.  5.  5.  4.  5.  5.  4.  5.  5.  4.  5.  5.  5.  5.  5.  5.  4.  4.]\n"
     ]
    }
   ],
   "source": [
    "ab_y_pred = ab_logistic.predict(abX_test)\n",
    "cd_y_pred = cd_logistic.predict(cdX_test)\n",
    "ef_y_pred = ef_logistic.predict(efX_test)\n",
    "\n",
    "ab_pred_size = ab_y_pred.shape[0]\n",
    "cd_pred_size = cd_y_pred.shape[0]\n",
    "ef_pred_size = ef_y_pred.shape[0]\n",
    "\n",
    "print(\"Predictions for Classes A & B: \\n{}\".format(ab_y_pred))\n",
    "print(\"Predictions for Classes C & D: \\n{}\".format(cd_y_pred))\n",
    "print(\"Predictions for Classes E & F: \\n{}\".format(ef_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the Test & Train Sets Labels for Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly Classified Labels: 618, 623\n"
     ]
    }
   ],
   "source": [
    "a_count = 0\n",
    "for a in range(ab_pred_size):\n",
    "    if ab_y_pred[a] == aby_test[a][0]:\n",
    "        a_count += 1\n",
    "        \n",
    "print(\"Correctly Classified Labels: {}, {}\".format(a_count, ab_test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly Classified Labels: 346, 364\n"
     ]
    }
   ],
   "source": [
    "c_count = 0\n",
    "for c in range(cd_pred_size):\n",
    "    if cd_y_pred[c] == cdy_test[c]:\n",
    "        c_count += 1\n",
    "        \n",
    "print(\"Correctly Classified Labels: {}, {}\".format(c_count, cd_test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly Classified Labels: 355, 360\n"
     ]
    }
   ],
   "source": [
    "e_count = 0\n",
    "for e in range(ef_pred_size):\n",
    "    if ef_y_pred[e] == efy_test[e]:\n",
    "        e_count += 1    \n",
    "        \n",
    "print(\"Correctly Classified Labels: {}, {}\".format(e_count, ef_test_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model's Precision for Each Pair of Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99       359\n",
      "        1.0       1.00      0.98      0.99       264\n",
      "\n",
      "avg / total       0.99      0.99      0.99       623\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        2.0       0.96      0.95      0.95       198\n",
      "        3.0       0.94      0.95      0.95       166\n",
      "\n",
      "avg / total       0.95      0.95      0.95       364\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        4.0       0.99      0.98      0.99       200\n",
      "        5.0       0.98      0.99      0.98       160\n",
      "\n",
      "avg / total       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(aby_test, ab_y_pred))\n",
    "print(classification_report(cdy_test, cd_y_pred))\n",
    "print(classification_report(efy_test, ef_y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
