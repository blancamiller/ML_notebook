{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW7 V2: Neural Net on Phoneme Data for Speech Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Objective:__ The aim of neural networks is to extract linear combinations of inputs as derived features to generate a nonlinear model of the data that makes predictions for new data sets [1]. A neural net takes a set of inputs, weights and biases them, and runs them through a series of hidden layers. These hidden layers are composed of nodes that each contain primitive function; nodes add together the weighted inputs it retrieves and applies the primitive function, an activation function that is usually the sigmoid activation function [2]. After traversing the network of hidden layers, the inputs are transformed into a set of outputs to make predictions about new data [1]. When given a set of data with known labels/targets estimating the optimal neural network weights and biases is computed using back-propogation. For this assignment, a data set of 5 phoneme classifications from continuous data of 50 male speakers were used.\n",
    "\n",
    "the output of a neuron can be the input of another\n",
    "\n",
    "__Forward Propogation:__ calculate \n",
    "\n",
    "__Backpropagation:__ update each existing weight in the network so that they cause the current output value to move closer the target/true output, which is achieved by minimizing the error for each output neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Variables__\n",
    "- x\n",
    "- y\n",
    "- y_hat\n",
    "\n",
    "__Equations__\n",
    "- Sum of Squares Error Function/Loss Function: Error = 1/2 * sum(target_j - output_j)^2\n",
    "- Sigmoid Function: sigmoid σ(v) = 1/(1 + e^(−v))\n",
    "- Weight Update Rule for Single Output Node for Hidden-to-Output Weights:\n",
    "\n",
    "\n",
    "__General Algorithm__\n",
    "\n",
    "_Assumptions_\n",
    "- binary classification \n",
    "- the hidden layer & output layer use the same activation function (this is due to doing binary classification)\n",
    "\n",
    "_Forward Propagation through the Network_\n",
    "- traverse the network forwards from the input layer nodes --> output layer nodes:\n",
    "    - calculate the net input for each hidden layer node and each output layer node\n",
    "    - \"squash\" each net input with the activation function\n",
    "_Backward Propogation through the Network_\n",
    "- traverse the network backwards from the output layer nodes --> input layer nodes:\n",
    "    - calculate the squared error for each output layer node: Error = computed_output(y_hat) - target_output(y)\n",
    "    - calculate the squared error for each hidden layer node: Error = actv_output(o)*(1-actv_output)*sum(weights*delta)\n",
    "    - calculate the difference in weights \n",
    "    \n",
    "    \n",
    "The algorithm terminates when the value of the error function is sufficiently small. This value is usually ... ?\n",
    "\n",
    "__References:__\n",
    "- https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "- https://brilliant.org/wiki/backpropagation/\n",
    "- Raul Rojas, Neural Networks: A systematic introduction, 1996. Retrieved from: http://page.mi.fu-berlin.de/rojas/neural/neuron.pdf\n",
    "- https://blogs.msdn.microsoft.com/uk_faculty_connection/2017/07/04/how-to-implement-the-backpropagation-using-python-and-numpy/\n",
    "\n",
    "- http://ufldl.stanford.edu/wiki/index.php/Backpropagation_Algorithm\n",
    "- http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/\n",
    "- https://en.wikipedia.org/wiki/Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
