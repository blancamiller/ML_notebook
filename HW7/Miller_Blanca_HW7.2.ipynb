{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW7 V2: Neural Net on Phoneme Data for Speech Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Objective:__ The aim of neural networks is to extract linear combinations of inputs as derived features to generate a nonlinear model of the data that makes predictions for new data sets [1]. A neural net takes a set of inputs, weights and biases them, and runs them through a series of hidden layers. These hidden layers are composed of nodes that each contain primitive function; nodes add together the weighted inputs they retrieve and applies the primitive function. These primitive functions are called 'activation functions' and they are usually the sigmoid/logistic function (the reLU and hyperbolic rangent functions are two others used) [2]  [3]. After traversing the network of hidden layers, the inputs are transformed into a set of outputs to make predictions about new data [1]. When given a set of data with known labels/targets estimating the optimal neural network weights and biases is computed using back-propogation. For this assignment, a data set of 5 phoneme classifications from continuous data of 50 male speakers were used.\n",
    "\n",
    "the output of a neuron can be the input of another\n",
    "\n",
    "__Forward Propogation:__ calculate \n",
    "\n",
    "__Backpropagation:__ update each existing weight in the network so that they cause the current output value to move closer the target/true output, which is achieved by minimizing the error for each output neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Variables__\n",
    "- x\n",
    "- y\n",
    "- y_hat\n",
    "\n",
    "__Equations__\n",
    "- Sum of Squares Error Function/Loss Function: Error = 1/2 * sum(target_j - output_j)^2\n",
    "- Sigmoid Function: sigmoid σ(v) = 1/(1 + e^(−v))\n",
    "- Weight Update Rule for Single Output Node for Hidden-to-Output Weights:\n",
    "\n",
    "\n",
    "__General Algorithm__\n",
    "\n",
    "_Assumptions_\n",
    "- binary classification \n",
    "- the hidden layer & output layer use the same activation function (this is due to doing binary classification)\n",
    "\n",
    "_Forward Propagation through the Network_\n",
    "- traverse the network forwards from the input layer nodes --> output layer nodes:\n",
    "    - calculate the net input for each hidden layer node and each output layer node\n",
    "    - \"squash\" each net input with the activation function\n",
    "_Backward Propogation through the Network_\n",
    "- traverse the network backwards from the output layer nodes --> input layer nodes:\n",
    "    - calculate the squared error for each output layer node: Error = computed_output(y_hat) - target_output(y)\n",
    "    - calculate the squared error for each hidden layer node: Error = actv_output(o)*(1-actv_output)*sum(weights*delta)\n",
    "    - calculate the difference in weights \n",
    "    \n",
    "    \n",
    "The algorithm terminates when the value of the error function is sufficiently small. This value is usually ... ?\n",
    "\n",
    "__References:__\n",
    "1. Trevor Hastie, Robert Tibshirani, Jerome Friedman, Elements of Statistical Learning: Data mining, inference, and prediction, 2002. Retrieved from: http://web.stanford.edu/~hastie/ElemStatLearn/main.html\n",
    "2. Raul Rojas, Neural Networks: A systematic introduction, 1996. Retrieved from: http://page.mi.fu-berlin.de/rojas/neural/neuron.pdf\n",
    "3. Aurelien Geron, Hands-on machine learning with scikit learn and tensorflow: concepts, tools, and techniques to build intelligent systems, Sebastopol, CA: O'Reilly Media, 2017.\n",
    "\n",
    "\n",
    "- https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "- https://brilliant.org/wiki/backpropagation/\n",
    "- https://blogs.msdn.microsoft.com/uk_faculty_connection/2017/07/04/how-to-implement-the-backpropagation-using-python-and-numpy/\n",
    "\n",
    "- http://ufldl.stanford.edu/wiki/index.php/Backpropagation_Algorithm\n",
    "- http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/\n",
    "- https://en.wikipedia.org/wiki/Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The Softmax / Logistic Function [3]:__ σ(v) = 1/(1 + e^(−v))\n",
    "\n",
    "This function is used to guarantee a gradient upon taking the derivative. We desire a function that produces a gradient so that when we implement gradient descent and iterate through the parameters, we are guaranteed to make progress and smoothly transition with each step toward convergence. Conversely, if we were to use a function that contains only flat segment, e.g. the step function, we wouldn't know that we were making progress because the gradient would be zero.  \n",
    "\n",
    "More specifically, this equation squashes the total net input, the value that is calculated by summing all of the inputs that go into a node. The term 'squashing' refers to the fact that we are taking values from the number line and bounding them into the range 0 to 1. This is the same range that the ReLU activation function squashes to. As a second example, if we were to be using the hyperbolic tangent function, the sqaushing range would be from -1 to 1.\n",
    "\n",
    "__Total Net Input:__ net = w1 x i1  +  w2 x i2 + ... + wN x wN + bias1 x 1\n",
    "\n",
    "This function sums all of the inputs for a given node. This summation is composed of products of weights and the values of the input nodes, including bias nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, bias):\n",
    "        self.bias = bias\n",
    "        self.weights = []\n",
    "        \n",
    "    def calc_total_net_input(self):\n",
    "        total = 0\n",
    "        for i in range(len(self.inputs)):\n",
    "            total += self.inputs[i] * self.weights[i]\n",
    "        return total + self.bias\n",
    "        \n",
    "    def calc_output(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = self.sigmoid(self.calc_total_net_input())\n",
    "        return self.output\n",
    "        \n",
    "    def sigmoid(self, total_net_input):\n",
    "        return 1.0 / 1.0 + np.exp(-total_net_input)\n",
    "    \n",
    "    def sqr_error(self, target):\n",
    "        return 0.5 * (target - self.output) ** 2\n",
    "        \n",
    "    def error_wrt_output(self):\n",
    "        return self.output * (1 - self.output)\n",
    "    \n",
    "    def pd_total_net_input_wrt_weight(self, index):\n",
    "        return self.inputs[index]\n",
    "    \n",
    "    # δ = ∂E/∂zⱼ = ∂E/∂yⱼ * dyⱼ/dzⱼ\n",
    "    def pd_error_wrt_total_net_input(self, target):\n",
    "        return self.pd_error_wrt_output(target) * self.pd_total_net_input_wrt_input()\n",
    "    \n",
    "    # = ∂E/∂yⱼ = -(tⱼ - yⱼ)\n",
    "    def pd_error_wrt_output(self, target_output):\n",
    "        return -(target_output - self.output)\n",
    "    \n",
    "    # dyⱼ/dzⱼ = yⱼ * (1 - yⱼ)\n",
    "    def pd_total_net_input_wrt_input(self):\n",
    "        return self.output * (1 - self.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronLayer:\n",
    "    \n",
    "    def __init__(self, num_neurons, bias):\n",
    "        \n",
    "        # every neuron in a layer shares the same bias\n",
    "        self.bias = bias if bias else random.random()\n",
    "        self.neurons = []\n",
    "        for i in range(num_neurons):\n",
    "            self.neurons.append(Neuron(self.bias))\n",
    "            \n",
    "    def inspect(self):\n",
    "        print('Neurons:', len(self.neurons))\n",
    "        for n in range(len(self.neurons)):\n",
    "            print(' Neuron', n)\n",
    "            for w in range(len(self.neurons[n].weights)):\n",
    "                print('  Weight:', self.neuron[n].weights[w])\n",
    "            print('  Bias:', self.bias)\n",
    "            \n",
    "    def feed_forward(self, inputs):\n",
    "        outputs = []\n",
    "        for neuron in self.neurons:\n",
    "            outputs.append(neuron.calc_output(inputs))\n",
    "        return outputs\n",
    "            \n",
    "    def get_outputs(self):\n",
    "        outputs = []\n",
    "        for neuron in self.neurons:\n",
    "            outputs.append(neuron.output)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    LEARNING_RATE = 0.5\n",
    "    \n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs, hidden_layer_weights=None, hidden_layer_bias=None, output_layer_weights=None, output_layer_bias=None):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.hidden_layer = NeuronLayer(num_hidden, hidden_layer_bias)\n",
    "        # ADD HIDDEN LAYER 2\n",
    "        self.output_layer = NeuronLayer(num_outputs, output_layer_bias)\n",
    "        \n",
    "        self.init_weights_from_inputs_to_hidden_layer_neurons(hidden_layer_weights)\n",
    "        self.init_weights_from_hidden_layer_neurons_to_output_layer_neurons(output_layer_weights)\n",
    "        \n",
    "    def init_weights_from_inputs_to_hidden_layer_neurons(self, hidden_layer_weights):\n",
    "        weight_num = 0 \n",
    "        for h in range(len(self.hidden_layer.neurons)):\n",
    "            for i in range(self.num_inputs):\n",
    "                if not hidden_layer_weights:\n",
    "                    self.hidden_layer.neurons[h].weights.append(random.random())\n",
    "                else:\n",
    "                    self.hidden_layer.neurons[h].weights.append(hidden_layer_weights[weight_num])\n",
    "                weight_num += 1\n",
    "                \n",
    "    def init_weights_from_hidden_layer_neurons_to_output_layer_neurons(self, output_layer_weights):\n",
    "        weight_num = 0 \n",
    "        for o in range(len(self.output_layer.neurons)):\n",
    "            for h in range(len(self.hidden_layer.neurons)):\n",
    "                if not output_layer_weights:\n",
    "                    self.output_layer.neurons[o].weights.append(random.random())\n",
    "                else:\n",
    "                    self.output_layer.neurons[o].weights.append(output_layer_weights[weight_num])\n",
    "                weight_num += 1\n",
    "                \n",
    "    def inspect(self):\n",
    "        print('------')\n",
    "        print('* Inputs: {}'.format(self.num_inputs))\n",
    "        print('------')\n",
    "        print('Hidden Layer')\n",
    "        self.hidden_layer.inspect()\n",
    "        print('------')\n",
    "        print('* Output Layer')\n",
    "        self.output_layer.inspect()\n",
    "        print('------')\n",
    "        \n",
    "    def feed_forward(self, inputs):\n",
    "        hidden_layer_outputs = self.hidden_layer.feed_forward(inputs)\n",
    "        # ADD HIDDEN LAYER 2\n",
    "        return self.output_layer.feed_forward(hidden_layer_outputs)\n",
    "    \n",
    "    def train(self, training_inputs, training_outputs):\n",
    "        self.feed_forward(training_inputs)\n",
    "        \n",
    "        # 1. Calculate deltas of output neurons\n",
    "        pd_errors_wrt_output_neuron_total_net_input = [0] * len(self.output_layer.neurons)\n",
    "        for o in range(len(self.output_layer.neurons)):\n",
    "            \n",
    "            # ∂E/∂zⱼ\n",
    "            pd_errors_wrt_output_neuron_total_net_input[o] = self.output_layer.neurons[o].pd_error_wrt_total_net_input(training_outputs[o])\n",
    "            print(o)\n",
    "        \n",
    "        # 2. Calculate deltas of hidden neurons\n",
    "        pd_errors_wrt_hidden_neuron_total_net_input = [0] * len(self.hidden_layer.neurons)\n",
    "        for h in range(len(self.hidden_layer.neurons)):\n",
    "            \n",
    "            # dE/dyⱼ = Σ ∂E/∂zⱼ * ∂z/∂yⱼ = Σ ∂E/∂zⱼ * wᵢⱼ\n",
    "            d_error_wrt_hidden_neuron_output =  0\n",
    "            for o in range(len(self.output_layer.neurons)):\n",
    "                d_error_wrt_hidden_neuron_output += pd_errors_wrt_output_neuron_total_net_input[o] * self.output_layer.neurons[o].weights[h]\n",
    "        \n",
    "            # ∂E/∂zⱼ = dE/dyⱼ * ∂zⱼ/∂\n",
    "            pd_errors_wrt_hidden_neuron_total_net_input[h] = d_error_wrt_hidden_neuron_output * self.hidden_layer.neurons[h].pd_total_net_input_wrt_input()\n",
    "            \n",
    "        # COMPUTE DELTA FOR HIDDEN LAYER 2 \n",
    "        \n",
    "            \n",
    "        # 3. Update weights of output neurons\n",
    "        for o in range(len(self.output_layer.neurons)):\n",
    "            for w_ho in range(len(self.output_layer.neurons[o].weights)):\n",
    "                \n",
    "                # ∂Eⱼ/∂wᵢⱼ = ∂E/∂zⱼ * ∂zⱼ/∂wᵢⱼ\n",
    "                pd_error_wrt_weight = pd_errors_wrt_output_neuron_total_net_input[o] * self.output_layer.neurons[o].pd_total_net_input_wrt_weight(w_ho)\n",
    "                \n",
    "                # Δw = α * ∂Eⱼ/∂wᵢ\n",
    "                self.output_layer.neurons[o].weights[w_ho] -= self.LEARNING_RATE * pd_error_wrt_weight\n",
    "                \n",
    "        # 4. Update hidden neuron weights\n",
    "        for h in range(len(self.hidden_layer.neurons)):\n",
    "            for w_ih in range(len(self.hidden_layer.neurons[h].weights)):\n",
    "                \n",
    "                # ∂Eⱼ/∂wᵢ = ∂E/∂zⱼ * ∂zⱼ/∂wᵢ\n",
    "                pd_error_wrt_weight = pd_errors_wrt_hidden_neuron_total_net_input[h] * self.hidden_layer.neurons[h].pd_total_net_input_wrt_weight(w_ih)\n",
    "                \n",
    "                # Δw = α * ∂Eⱼ/∂wᵢ\n",
    "                self.hidden_layer.neurons[h].weights[w_ih] -= self.LEARNING_RATE * pd_error_wrt_weight\n",
    "                \n",
    "            # UPDATE HIDDEN LAYER 2\n",
    "                \n",
    "                \n",
    "        \n",
    "    def calculate_total_error(self, training_sets):\n",
    "        total_error = 0\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward(training_inputs)\n",
    "            for o in range(len(training_outputs)):\n",
    "                total_error += self.output_layer.neurons[o].sqr_error(training_outputs[o])\n",
    "            return total_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnn = NeuralNetwork(2, 2, 2, \\n                   hidden_layer_weights=[0.15, 0.2, 0.25, 0.3], \\n                   hidden_layer_bias=0.35, \\n                   output_layer_weights=[0.4, 0.45, 0.5, 0.55], \\n                   output_layer_bias=0.6)\\n\\nfor i in range(10000):\\n    nn.train([0.05, 0.1], [0.01, 0.99])\\n    \\nprint(i, round(nn.calculate_total_error([[[0.05, 0.1], [0.01, 0.99]]]), 9))\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "nn = NeuralNetwork(2, 2, 2, \n",
    "                   hidden_layer_weights=[0.15, 0.2, 0.25, 0.3], \n",
    "                   hidden_layer_bias=0.35, \n",
    "                   output_layer_weights=[0.4, 0.45, 0.5, 0.55], \n",
    "                   output_layer_bias=0.6)\n",
    "\n",
    "for i in range(10000):\n",
    "    nn.train([0.05, 0.1], [0.01, 0.99])\n",
    "    \n",
    "print(i, round(nn.calculate_total_error([[[0.05, 0.1], [0.01, 0.99]]]), 9))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(num_inputs, \n",
    "num_hidden, \n",
    "num_outputs, \n",
    "hidden_layer_weights=None, \n",
    "hidden_layer_bias=None, \n",
    "output_layer_weights=None, \n",
    "output_layer_bias=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load phoneme data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('five_phonemes.txt', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4509, 259)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   row.names       x.1       x.2       x.3       x.4       x.5       x.6  \\\n",
      "0          1   9.85770   9.20711   9.81689   9.01692   9.05675   8.92518   \n",
      "1          2  13.23079  14.19189  15.34428  18.11737  19.53875  18.32726   \n",
      "2          3  10.81889   9.07615   9.77940  12.20135  12.59005  10.53364   \n",
      "3          4  10.53679   9.12147  10.84621  13.92331  13.52476  10.27831   \n",
      "4          5  12.96705  13.69454  14.91182  18.22292  18.45390  17.25760   \n",
      "\n",
      "        x.7       x.8       x.9         ...              x.249     x.250  \\\n",
      "0  11.28308  11.52980  10.79713         ...           12.68076  11.20767   \n",
      "1  17.34169  17.16861  19.63557         ...            8.45714   8.77266   \n",
      "2   8.54693   9.46049  11.96755         ...            5.00824   5.51019   \n",
      "3   8.97459  11.57109  12.35839         ...            5.85688   5.40324   \n",
      "4  17.79614  17.76387  18.99632         ...            8.00151   7.58624   \n",
      "\n",
      "      x.251     x.252     x.253     x.254     x.255    x.256    g  \\\n",
      "0  13.69394  13.72055  12.16628  12.92489  12.51195  9.75527   sh   \n",
      "1   9.59717   8.45336   7.57730   5.38504   9.43063  8.59328   iy   \n",
      "2   5.95725   7.04992   7.02469   6.58416   6.27058  3.85042  dcl   \n",
      "3   6.07126   5.30651   4.27412   3.63384   3.22823  4.63123  dcl   \n",
      "4   6.65202   7.69109   6.93683   7.03600   7.01278  8.52197   aa   \n",
      "\n",
      "               speaker  \n",
      "0  train.dr1.mcpm0.sa1  \n",
      "1  train.dr1.mcpm0.sa1  \n",
      "2  train.dr1.mcpm0.sa1  \n",
      "3  train.dr1.mcpm0.sa1  \n",
      "4  train.dr1.mcpm0.sa1  \n",
      "\n",
      "[5 rows x 259 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Data Frame Into Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   row.names       x.1       x.2       x.3       x.4       x.5       x.6  \\\n",
      "0          1   9.85770   9.20711   9.81689   9.01692   9.05675   8.92518   \n",
      "1          2  13.23079  14.19189  15.34428  18.11737  19.53875  18.32726   \n",
      "2          3  10.81889   9.07615   9.77940  12.20135  12.59005  10.53364   \n",
      "3          4  10.53679   9.12147  10.84621  13.92331  13.52476  10.27831   \n",
      "4          5  12.96705  13.69454  14.91182  18.22292  18.45390  17.25760   \n",
      "\n",
      "        x.7       x.8       x.9         ...              x.249     x.250  \\\n",
      "0  11.28308  11.52980  10.79713         ...           12.68076  11.20767   \n",
      "1  17.34169  17.16861  19.63557         ...            8.45714   8.77266   \n",
      "2   8.54693   9.46049  11.96755         ...            5.00824   5.51019   \n",
      "3   8.97459  11.57109  12.35839         ...            5.85688   5.40324   \n",
      "4  17.79614  17.76387  18.99632         ...            8.00151   7.58624   \n",
      "\n",
      "      x.251     x.252     x.253     x.254     x.255    x.256    g  \\\n",
      "0  13.69394  13.72055  12.16628  12.92489  12.51195  9.75527   sh   \n",
      "1   9.59717   8.45336   7.57730   5.38504   9.43063  8.59328   iy   \n",
      "2   5.95725   7.04992   7.02469   6.58416   6.27058  3.85042  dcl   \n",
      "3   6.07126   5.30651   4.27412   3.63384   3.22823  4.63123  dcl   \n",
      "4   6.65202   7.69109   6.93683   7.03600   7.01278  8.52197   aa   \n",
      "\n",
      "               speaker  \n",
      "0  train.dr1.mcpm0.sa1  \n",
      "1  train.dr1.mcpm0.sa1  \n",
      "2  train.dr1.mcpm0.sa1  \n",
      "3  train.dr1.mcpm0.sa1  \n",
      "4  train.dr1.mcpm0.sa1  \n",
      "\n",
      "[5 rows x 259 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse data values: get columns 1-(last-1) for all rows\n",
    "X_phonemes = data_set[1:4509, 1:257]\n",
    "\n",
    "# Parse labels: get last column for all rows \n",
    "y_phonemes = data_set[1:4509, 257]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: (4508, 256)\n",
      "Labels: (4508,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data: {}\".format(X_phonemes.shape))\n",
    "print(\"Labels: {}\".format(y_phonemes.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13.230789999999999 14.191889999999999 15.34428 ... 5.38504 9.43063\n",
      "  8.59328]\n",
      " [10.81889 9.07615 9.7794 ... 6.584160000000001 6.270580000000001\n",
      "  3.8504199999999997]\n",
      " [10.53679 9.12147 10.846210000000001 ... 3.63384 3.22823 4.63123]\n",
      " [12.96705 13.69454 14.91182 ... 7.036 7.01278 8.52197]]\n"
     ]
    }
   ],
   "source": [
    "print(X_phonemes[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iy' 'dcl' 'dcl' 'aa']\n"
     ]
    }
   ],
   "source": [
    "print(y_phonemes[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Test & Training Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate 2/3 of the data set as training & 1/3 as testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_phonemes, y_phonemes, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme Training Data: (3020, 256)\n",
      "Phoneme Training Labels: (3020,)\n",
      "Phoneme Testing Data: (1488, 256)\n",
      "Phoneme Testing Labels: (1488,)\n"
     ]
    }
   ],
   "source": [
    "# print data & label set dimensionality for verification\n",
    "print(\"Phoneme Training Data: {}\".format(X_train.shape))\n",
    "print(\"Phoneme Training Labels: {}\".format(y_train.shape))\n",
    "print(\"Phoneme Testing Data: {}\".format(X_test.shape))\n",
    "print(\"Phoneme Testing Labels: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.86016 13.8623 16.86945 ... 7.34628 6.869330000000001 6.1774]\n",
      " [9.60178 10.114419999999999 13.35065 ... 5.24709 5.95986 6.13764]\n",
      " [10.52202 13.2941 18.177960000000002 ... 9.74872 9.5983 4.40412]\n",
      " [12.65137 13.34291 16.5692 ... 6.67583 9.30155 10.386510000000001]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.05765 12.05285 16.79644 ... 7.602810000000001 8.59259 8.72819]\n",
      " [7.680619999999999 11.87683 14.008510000000001 ... 5.45096\n",
      "  4.618119999999999 6.64807]\n",
      " [11.035689999999999 17.225839999999998 18.60887 ... 8.56829 6.47623\n",
      "  4.81701]\n",
      " [10.12635 12.881839999999999 16.78079 ... 7.032489999999999 5.84967\n",
      "  6.13477]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ao' 'dcl' 'iy' 'ao']\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iy' 'dcl' 'ao' 'ao']\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the Phoneme Classifiers from Strings to Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_class_to_int_class(y):\n",
    "    for i in range(len(y)):\n",
    "    \n",
    "        if y[i] == 'aa':\n",
    "            y[i] = [0]\n",
    "        elif y[i] == 'ao':\n",
    "            y[i] = [1]\n",
    "        elif y[i] == 'dcl':\n",
    "            y[i] = [2]\n",
    "        elif y[i] == 'iy':\n",
    "            y[i] = [3]\n",
    "        elif y[i] == 'sh':\n",
    "            y[i] = [4]\n",
    "            \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_int_train = convert_string_class_to_int_class(y_train)\n",
    "y_int_test = convert_string_class_to_int_class(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize Data to Obtain Similar Inputs & Weight Magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blanca/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# set axis to 1 to standardize by sample/vector, rather than by feature \n",
    "X_train = preprocessing.scale(X_train, axis=1)\n",
    "X_test = preprocessing.scale(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After preprocessing the data matrices, add in their corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_train = zip(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(len(X_train), 2, len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[-6.33767749e-01 -2.85736761e-01  9.22402923e-01  1.69650646e+00\n",
      "  1.52147613e+00  2.87225556e-01  9.73691499e-01  2.08043483e+00\n",
      "  2.18958800e+00  1.14952716e+00  6.13224032e-01  2.08242641e+00\n",
      "  2.45703626e+00  1.81341101e+00  8.51753595e-01  2.41041918e+00\n",
      "  3.07468665e+00  2.76809517e+00  1.05319410e+00  1.74117277e+00\n",
      "  2.70473470e+00  2.68910135e+00  1.67951547e+00  1.10667015e+00\n",
      "  2.44287755e+00  2.68952851e+00  1.92937418e+00  8.60560615e-01\n",
      "  1.91843410e+00  2.47348854e+00  2.03830425e+00  8.19341478e-01\n",
      "  1.48757578e+00  2.49369272e+00  2.57694449e+00  1.88013703e+00\n",
      "  7.00850746e-01  1.56108460e+00  1.69575010e+00  8.90238393e-01\n",
      " -1.08225123e-01  1.04436259e+00  1.46743962e+00  8.95062256e-01\n",
      " -6.80398661e-02  4.85436547e-01  1.15164662e+00  8.42293599e-01\n",
      " -7.96710085e-02 -9.07335173e-02  8.02823896e-01  8.16857447e-01\n",
      "  3.22654734e-02 -9.04774728e-01  4.82685884e-01  7.86216529e-01\n",
      "  1.30892119e-01 -5.28271247e-01  2.52492652e-01  8.28698086e-01\n",
      "  3.60718052e-01 -5.59502565e-01 -4.85893312e-02  7.38889343e-01\n",
      "  5.79274699e-01 -5.65175531e-02 -8.47946734e-01  2.72628813e-01\n",
      "  4.60585353e-01 -1.85836811e-01 -9.17793445e-01 -5.67569778e-02\n",
      "  4.92047933e-01  1.13835831e-01 -7.20232710e-01  2.94274981e-01\n",
      "  8.78789540e-01  5.78352370e-01  2.48920327e-01  8.45710843e-01\n",
      "  1.08933906e+00  7.72218347e-01 -7.76285293e-01  7.86568758e-04\n",
      "  6.51249025e-01  7.07532871e-01 -1.54692557e-01 -2.53490610e-01\n",
      "  2.89837462e-01  6.19519812e-01  2.04493444e-01 -5.59540655e-01\n",
      " -1.72102541e-01  4.52548302e-01  3.20883770e-01 -4.08776563e-01\n",
      " -4.47827274e-01  3.84997891e-01  5.44813869e-01 -7.80875407e-02\n",
      " -6.81043242e-01  2.52898042e-01  6.89581461e-01  2.81166479e-01\n",
      " -3.43263984e-01  3.89160616e-01  9.38555927e-01  6.52530491e-01\n",
      " -3.85389125e-01  7.52177179e-02  7.36886882e-01  5.92701527e-01\n",
      " -1.81714898e-01 -2.16262792e-01  4.80838505e-01  6.77857814e-01\n",
      "  1.11719099e-01 -1.13661945e+00  4.18914341e-02  5.18931516e-01\n",
      "  1.04332304e-01 -4.62290701e-01 -4.39099007e-03  6.63579396e-01\n",
      "  5.63497157e-01 -3.42455925e-01 -1.60063265e+00  2.85769963e-01\n",
      "  4.03871631e-01 -1.96733589e-02 -1.48520818e+00 -5.87153395e-01\n",
      " -4.73832059e-01 -8.95396354e-01 -7.47187032e-01 -8.99782179e-01\n",
      " -2.35375955e-01 -2.87322950e-01 -7.35460664e-01 -8.98729254e-01\n",
      " -1.53733475e+00 -6.31972064e-01 -1.30949767e+00 -1.68144936e+00\n",
      " -1.07628987e+00 -9.31182182e-01 -1.75232451e+00 -1.86001665e+00\n",
      " -1.40875009e+00 -1.19939769e+00 -1.55724781e+00 -1.48426409e+00\n",
      " -9.38343157e-01 -9.11870405e-01 -1.05872752e+00 -1.97180077e+00\n",
      " -1.08824750e+00 -8.84151556e-01 -7.27562370e-01 -1.41045599e+00\n",
      " -1.02153779e+00 -7.52862485e-01 -6.19633531e-01 -9.13739550e-01\n",
      " -9.46236009e-01 -9.89582760e-01 -4.85574752e-01 -6.94625151e-01\n",
      " -1.19805908e+00 -6.85644005e-01 -1.46372549e-01 -3.18418231e-01\n",
      " -7.46362649e-01 -7.97025457e-01 -1.94377199e-01  2.29113525e-03\n",
      " -3.75507415e-01 -1.09012208e+00 -2.55996407e-01 -1.09746014e-01\n",
      " -4.66162307e-01 -8.34383870e-01 -8.89323673e-01 -5.47993856e-01\n",
      " -5.69634582e-01 -1.07153946e+00 -5.89958473e-01 -2.11928661e-01\n",
      " -1.70423847e-01 -4.77377177e-01 -4.34283454e-01 -3.19291587e-01\n",
      "  4.64132958e-02 -6.51314004e-02 -2.04631649e-01 -1.13900576e-01\n",
      "  3.28039303e-01  2.87377917e-01  1.01173530e-01 -1.27362773e-01\n",
      "  1.52960002e-01  1.71297756e-01 -1.30129761e-01 -7.50648041e-02\n",
      "  6.10998236e-02  2.33423020e-01  4.31076027e-02 -3.58856516e-01\n",
      " -5.10752434e-01 -1.66511430e-01 -2.40703155e-01 -3.56671766e-01\n",
      " -3.00241000e-01  1.15155388e-01  1.72133022e-01 -9.32801253e-02\n",
      " -3.50754167e-01 -1.00968923e-01 -4.27669581e-02 -5.66824063e-01\n",
      " -6.67189259e-01 -2.96595215e-01 -1.11772962e-01 -3.25296249e-01\n",
      " -5.90075465e-01 -6.56110426e-01 -2.93251432e-01 -5.23754827e-01\n",
      " -7.51918390e-01 -1.00845378e+00 -4.79695243e-01 -4.76950022e-01\n",
      " -6.05104805e-01 -1.13594198e+00 -6.77141708e-01 -7.09915682e-01\n",
      " -8.61898664e-01 -1.10052889e+00 -7.59275258e-01 -4.91492351e-01\n",
      " -6.05093922e-01 -1.01682276e+00 -7.36674112e-01 -5.76855413e-01\n",
      " -8.18924653e-01 -1.12469446e+00 -1.03126170e+00 -6.36216411e-01\n",
      " -6.34379915e-01 -1.00914212e+00 -8.71516462e-01 -1.01782399e+00\n",
      " -7.71281862e-01 -1.50036540e+00 -8.18345137e-01 -3.01805127e+00]\n",
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f394d2992b15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_total_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXy_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-caee39265248>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_inputs, training_outputs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;31m# ∂E/∂zⱼ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mpd_errors_wrt_output_neuron_total_net_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpd_error_wrt_total_net_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    training_inputs, training_outputs = random.choice(Xy_train)\n",
    "    print(training_outputs)\n",
    "    print(training_inputs)\n",
    "    nn.train(training_inputs, training_outputs)\n",
    "    print(i, nn.calculate_total_error(Xy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
